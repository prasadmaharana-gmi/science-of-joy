{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b2668f",
   "metadata": {},
   "source": [
    "# Facts up Front Test Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "006fc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to illustrate\n",
    "# template matching\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7812d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the main image\n",
    "img = cv2.imread(r'C:\\Users\\G670813\\OneDrive - General Mills\\ITQ-prasad\\itq-analytics\\Computer Vision\\Facts_Up_Front\\test_images\\0016000123991_0.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# load the temp image\n",
    "temp = cv2.imread(r'C:\\Users\\G670813\\OneDrive - General Mills\\ITQ-prasad\\itq-analytics\\Computer Vision\\Facts_Up_Front\\test_images\\ref.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "template = cv2.Canny(temp, 50, 200)\n",
    "(tH, tW) = template.shape[:2]\n",
    "cv2.imshow(\"Template\", template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d724b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # save the image dimensions\n",
    "# W, H = temp.shape[:2]\n",
    "\n",
    "# # Define a minimum threshold\n",
    "# thresh = 0.4\n",
    "\n",
    "# # # img_temp = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "# # # temp_temp = cv2.cvtColor(temp,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # # Converting them to grayscale\n",
    "# # img_gray = cv2.Canny(img,50,200)\n",
    "# # temp_gray= cv2.Canny(temp,50,200)\n",
    "\n",
    "# # Passing the image to matchTemplate method\n",
    "# match = cv2.matchTemplate(\n",
    "# \timage=img_gray, templ=temp_gray,\n",
    "# method=cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# # Select rectangles with\n",
    "# # confidence greater than threshold\n",
    "# (y_points, x_points) = np.where(match >= thresh)\n",
    "\n",
    "# # initialize our list of rectangles\n",
    "# boxes = list()\n",
    "\n",
    "# # loop over the starting (x, y)-coordinates again\n",
    "# for (x, y) in zip(x_points, y_points):\n",
    "\t\n",
    "# \t# update our list of rectangles\n",
    "# \tboxes.append((x, y, x + W, y + H))\n",
    "\n",
    "# # apply non-maxima suppression to the rectangles\n",
    "# # this will create a single bounding box\n",
    "# boxes = non_max_suppression(np.array(boxes))\n",
    "\n",
    "# # loop over the final bounding boxes\n",
    "# for (x1, y1, x2, y2) in boxes:\n",
    "\t\n",
    "# \t# draw the bounding box on the image\n",
    "# \tcv2.rectangle(img, (x1, y1), (x2, y2),\n",
    "# \t\t\t\t(255, 0, 0), 3)\n",
    "\n",
    "# # Show the template and the final output\n",
    "# cv2.namedWindow('Rescaled',cv2.WINDOW_NORMAL)\n",
    "# cv2.imshow(\"template\", temp_gray)\n",
    "# cv2.imshow(\"Rescaled\", img)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# # destroy all the windows\n",
    "# # manually to be on the safe side\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adf00d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9920\\2140907206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# if the resized image is smaller than the template, then break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# from the loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mresized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtH\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtW\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0medged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tH' is not defined"
     ]
    }
   ],
   "source": [
    "found = None\n",
    "# loop over the scales of the image\n",
    "for scale in np.linspace(0.2, 1.0, 20)[::-1]:\n",
    "    # resize the image according to the scale, and keep track\n",
    "    # of the ratio of the resizing\n",
    "    resized = imutils.resize(img, width = int(img.shape[1] * scale))\n",
    "    r = img.shape[1] / float(resized.shape[1])\n",
    "    # if the resized image is smaller than the template, then break\n",
    "    # from the loop\n",
    "    if resized.shape[0] < tH or resized.shape[1] < tW:\n",
    "        break\n",
    "    edged = cv2.Canny(resized, 50, 200)\n",
    "    result = cv2.matchTemplate(edged, temp, cv2.TM_CCOEFF)\n",
    "    (_, maxVal, _, maxLoc) = cv2.minMaxLoc(result)\n",
    "    # check to see if the iteration should be visualized\n",
    "    if args.get(\"visualize\", False):\n",
    "        # draw a bounding box around the detected region\n",
    "        clone = np.dstack([edged, edged, edged])\n",
    "        cv2.rectangle(clone, (maxLoc[0], maxLoc[1]),\n",
    "            (maxLoc[0] + tW, maxLoc[1] + tH), (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Visualize\", clone)\n",
    "        cv2.waitKey(0)\n",
    "    # if we have found a new maximum correlation value, then update\n",
    "    # the bookkeeping variable\n",
    "    if found is None or maxVal > found[0]:\n",
    "        found = (maxVal, maxLoc, r)\n",
    "# unpack the bookkeeping variable and compute the (x, y) coordinates\n",
    "# of the bounding box based on the resized ratio\n",
    "(_, maxLoc, r) = found\n",
    "(startX, startY) = (int(maxLoc[0] * r), int(maxLoc[1] * r))\n",
    "(endX, endY) = (int((maxLoc[0] + tW) * r), int((maxLoc[1] + tH) * r))\n",
    "# draw a bounding box around the detected result and display the image\n",
    "cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "cv2.namedWindow('Rescaled',cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Rescaled\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a89315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
